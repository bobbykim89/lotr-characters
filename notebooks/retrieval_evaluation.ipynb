{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa96abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from tqdm import tqdm\n",
    "from os import environ\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd90e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dist/qdrant_records.json\", 'r') as file:\n",
    "    qdrant_records = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3b979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = environ.get('QDRANT_URL')\n",
    "QDRANT_API_KEY = environ.get('QDRANT_API_KEY')\n",
    "COLLECTION_NAME = 'lotr-characters'\n",
    "EMBEDDING_DIMENSION = 512\n",
    "JINA_EMBEDDING_MODEL = \"jina-embeddings-v4\"\n",
    "JINA_URL = \"https://api.jina.ai/v1/embeddings\"\n",
    "JINA_API_KEY = environ.get('JINA_API_KEY')\n",
    "QUERYING_TASK = \"retrieval.query\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_TEMPERATURE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb18bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "qd_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2253e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt (payload: dict[str,str])-> tuple[str, str]:\n",
    "    raw_user_prompt = \"\"\"\n",
    "Payload:\n",
    "{payload}\n",
    "\"\"\".strip()\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an assistant that generates evaluation questions to test retrieval quality on character data.\n",
    "You will receive a JSON object describing a fictional character, which may include fields such as name, race, gender, birth, death, spouse, realm, biography, and others.\n",
    "\n",
    "Your task:\n",
    "1. Read and understand the JSON payload carefully.\n",
    "2. Generate exactly 5 diverse and specific questions that can be answered using the information in the payload.\n",
    "3. Focus on factual, grounded details â€” such as relationships, timeline, characteristics, or key events mentioned in the biography.\n",
    "4. Avoid trivial or repetitive questions.\n",
    "5. Do not include any reasoning, explanations, or text outside the JSON array.\n",
    "\n",
    "Output valid JSON only (no code blocks, no extra text):\n",
    "[\"Question 1\", \"Question 2\", \"Question 3\", \"Question 4\", \"Question 5\"]\n",
    "\n",
    "If a field is null or missing, do not ask about it. If there is limited information, create general but relevant questions based on available content.\n",
    "\"\"\".strip()\n",
    "    user_prompt = raw_user_prompt.format(payload=payload).strip()\n",
    "    \n",
    "    return user_prompt, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5214d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_records ()->list[dict]:\n",
    "    \"\"\"\n",
    "    format character information\n",
    "    \"\"\"\n",
    "    formatted_records = []\n",
    "    for record in tqdm(qdrant_records):\n",
    "        basic_fields = ['name', 'race', 'gender', 'realm', 'culture', 'birth', 'death', 'spouse', 'hair', 'height', 'biography', 'history']\n",
    "        character = {\n",
    "            \"id\": record[\"id\"]\n",
    "        }\n",
    "        character.update([(field, record[\"payload\"][field]) for field in basic_fields if record[\"payload\"].get(field)])\n",
    "        formatted_records.append(character)\n",
    "\n",
    "    return formatted_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caae4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt: str, system_prompt: str)-> list[str]:\n",
    "    \"\"\"\n",
    "    llm function to call openAI with our specific prompts\n",
    "    \"\"\"\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=OPENAI_TEMPERATURE\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbecad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(ctx: dict[str,str])->dict:\n",
    "    user_prompt, system_prompt = format_prompt(ctx)\n",
    "    questions = llm(user_prompt=user_prompt, system_prompt=system_prompt)\n",
    "    return {\n",
    "        \"id\": ctx['id'],\n",
    "        \"questions\": json.loads(questions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "462e6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions_and_save_json():\n",
    "    records = format_records()\n",
    "    formatted_questions = []\n",
    "    for record in tqdm(records):\n",
    "        questions = generate_question(ctx=record)\n",
    "        formatted_questions.append(questions)\n",
    "    \n",
    "    with open('../dist/golden_questions.json', 'w') as file:\n",
    "        json.dump(formatted_questions, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49b64bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 749/749 [00:00<00:00, 251947.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 749/749 [24:29<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "generate_questions_and_save_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "540c2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json_file (file_path: str):\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "def save_json_file (file_path: str, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b6d3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jina_embedding(input_text: str)-> list:\n",
    "    \"\"\"\n",
    "    Create embedding using Jina API\n",
    "    Returns a single embedding vector (list of floats)\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {JINA_API_KEY}\",\n",
    "    }\n",
    "    data = {\n",
    "        \"input\": [input_text],\n",
    "        \"model\": JINA_EMBEDDING_MODEL,\n",
    "        \"dimensions\": EMBEDDING_DIMENSION,\n",
    "        \"task\": QUERYING_TASK,\n",
    "        \"late_chunking\": True,\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(url=JINA_URL, headers=headers, json=data, timeout=30)\n",
    "        if res.status_code == 200:\n",
    "            embedding = res.json()[\"data\"][0][\"embedding\"]\n",
    "            return embedding\n",
    "        else:\n",
    "            raise Exception(f\"Jina API error: {res.status_code} - {res.text}\")\n",
    "    except requests.RequestException as e:\n",
    "        raise Exception(f\"Request failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701ab584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, limit: int = 5, threshold = 0.3):\n",
    "    \"\"\"\n",
    "    Updated search function to use Jina API for query embedding\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create embedding for the search query using Jina API\n",
    "        query_embedding = create_jina_embedding(input_text=query)\n",
    "        \n",
    "        query_points = qd_client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=query_embedding,\n",
    "            limit=limit,\n",
    "            with_payload=True,\n",
    "            score_threshold=threshold\n",
    "        )\n",
    "        \n",
    "        # return query_points\n",
    "        results = [{\"id\": point.id, \"score\": point.score, **point.payload} for point in query_points.points]\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28ba47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_search_result(golden_questions=None, previous_results=None, start_index=0, requests_per_minute=400):\n",
    "    search_results = previous_results if previous_results is not None else []\n",
    "    current_index = start_index\n",
    "\n",
    "    # Calculate delay between requests to stay under rate limit\n",
    "    delay_seconds = 60.0 / requests_per_minute\n",
    "\n",
    "    try:\n",
    "        for obj in tqdm(golden_questions, desc=\"Processing documents\"):\n",
    "            doc_id = obj[\"id\"]\n",
    "            for q_idx, question in enumerate(obj[\"questions\"]):\n",
    "                if current_index < start_index:\n",
    "                    current_index += 1\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    results = search(query=question, limit=5, threshold=0.3)\n",
    "                    if results is None:\n",
    "                        raise ValueError(\"Search returned None\")\n",
    "                    search_result = {\n",
    "                        \"id\": doc_id,\n",
    "                        \"question\": question,\n",
    "                        \"question_idx\": q_idx,\n",
    "                        \"search_results\": results\n",
    "                    }\n",
    "                    search_results.append(search_result)\n",
    "                    current_index += 1\n",
    "\n",
    "                    # Add delay to respect rate limit\n",
    "                    time.sleep(delay_seconds)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nâŒ Error at index {current_index}\")\n",
    "                    print(f\"   Document ID: {doc_id}\")\n",
    "                    print(f\"   Question {q_idx + 1}/{len(obj['questions'])}: {question}\")\n",
    "                    print(f\"   Error: {type(e).__name__}: {str(e)}\")\n",
    "                    print(f\"\\nðŸ’¾ Processed {len(search_results)} questions before failure\")\n",
    "                    print(f\"   Returning (relevance_total, {current_index}) for resume\")\n",
    "                    return search_results, current_index\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nâš ï¸  Interrupted by user at index {current_index}\")\n",
    "        print(f\"ðŸ’¾ Processed {len(search_results)} questions\")\n",
    "        return search_results, current_index\n",
    "    \n",
    "    return search_results, current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd33693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + (1 / (rank + 1))\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb775671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(relevance_total):\n",
    "    return {\n",
    "        \"hit_rate\": hit_rate(relevance_total=relevance_total),\n",
    "        \"mrr\": mrr(relevance_total=relevance_total)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9d0933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 749\n"
     ]
    }
   ],
   "source": [
    "all_golden_questions = open_json_file(file_path=\"../dist/golden_questions.json\")\n",
    "total_entries = len(all_golden_questions)\n",
    "print(f\"Total entries: {total_entries}\")\n",
    "batches = []\n",
    "for batch_num in range(0, total_entries, 100):\n",
    "    batch_end = min(batch_num + 100, total_entries)\n",
    "    batches.append([batch_num, batch_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae13b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_questions_batch_1 = all_golden_questions[batches[0][0]:batches[0][1]]\n",
    "golden_questions_batch_2 = all_golden_questions[batches[1][0]:batches[1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "089232e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:07<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "search_results, last_index = get_formatted_search_result(golden_questions=golden_questions_batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a159303",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json_file(file_path=\"../dist/retrieval_search_results.json\", data=search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62ca169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(data: list[dict], filters: dict):\n",
    "    \"\"\"\n",
    "    Filter search results based on limit and threshold.\n",
    "    Args:\n",
    "        data: List of result objects\n",
    "        filters: Dictionary with 'limit' (int) and 'threshold' (float)\n",
    "    Returns:\n",
    "        Filtered data with same structure\n",
    "    \"\"\"\n",
    "    limit = filters.get('limit')\n",
    "    threshold = filters.get('threshold')\n",
    "\n",
    "    filtered_data = []\n",
    "\n",
    "    for entry in tqdm(data, desc=f\"Filtering results satifying {filters}\"):\n",
    "        filtered_entry = entry.copy()\n",
    "        results = entry['search_results']\n",
    "\n",
    "        # apply limit (top x items)\n",
    "        if limit is not None:\n",
    "            results = results[:limit]\n",
    "        # apply threshold filter\n",
    "        if threshold is not None:\n",
    "            results = [r for r in results if r.get('score', 0) > threshold]\n",
    "        # update the entry with filtered results\n",
    "        filtered_entry['search_results'] = results\n",
    "        filtered_data.append(filtered_entry)\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86138cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategies_list():\n",
    "    ## list of strategies\n",
    "    limits = [3, 4, 5]\n",
    "    thresholds = [0.3, 0.5, 0.7]\n",
    "    strategies = []\n",
    "\n",
    "    for limit, threshold in itertools.product(limits, thresholds):\n",
    "        strategy = {\"limit\": limit, \"threshold\": threshold}\n",
    "        strategies.append(strategy)\n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd4aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_relevance_matrix(data: list[dict]):\n",
    "    \"\"\"\n",
    "    Create relevance matrix based on given data\n",
    "    Args:\n",
    "        data: List of result objects\n",
    "    Returns:\n",
    "        relevance matrix nested list of boolean\n",
    "    \"\"\"\n",
    "    relevance_total = []\n",
    "    for obj in tqdm(data):\n",
    "        obj_id = obj[\"id\"]\n",
    "        relevance = [result['id'] == obj_id for result in obj[\"search_results\"]]\n",
    "        relevance_total.append(relevance)\n",
    "    \n",
    "    return relevance_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77297b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluations_per_strategy():\n",
    "    search_results = open_json_file(file_path=\"../dist/retrieval_search_results.json\")\n",
    "    strategies = get_strategies_list()\n",
    "    \n",
    "    results = []\n",
    "    for strategy in tqdm(strategies):\n",
    "        filtered_results = filter_results(data=search_results, filters=strategy)\n",
    "        relevance_total = make_relevance_matrix(data=filtered_results)\n",
    "        eval = evaluate(relevance_total=relevance_total)\n",
    "        formatted_evaluation = {**strategy, **eval}\n",
    "        results.append(formatted_evaluation)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cea6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_evaluation_result(results: list[dict]):\n",
    "    highest_hit_rate = max(results, key=lambda x: x['hit_rate'])\n",
    "    highest_mrr = max(results, key=lambda x: x['mrr'])\n",
    "\n",
    "    print(f\"Highest Hit Rate: {highest_hit_rate}\")\n",
    "    print(f\"Highest MRR: {highest_mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ece401c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering results satifying {'limit': 3, 'threshold': 0.3}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 529583.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1008246.15it/s]\n",
      "Filtering results satifying {'limit': 3, 'threshold': 0.5}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1131149.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1923992.66it/s]\n",
      "Filtering results satifying {'limit': 3, 'threshold': 0.7}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 883383.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1343467.01it/s]\n",
      "Filtering results satifying {'limit': 4, 'threshold': 0.3}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1225687.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 904334.63it/s]\n",
      "Filtering results satifying {'limit': 4, 'threshold': 0.5}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 718202.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 398698.10it/s]\n",
      "Filtering results satifying {'limit': 4, 'threshold': 0.7}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1091698.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1538629.49it/s]\n",
      "Filtering results satifying {'limit': 5, 'threshold': 0.3}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 995798.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1152281.32it/s]\n",
      "Filtering results satifying {'limit': 5, 'threshold': 0.5}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 351340.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1470653.58it/s]\n",
      "Filtering results satifying {'limit': 5, 'threshold': 0.7}: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 662188.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1608245.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 180.94it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_result = generate_evaluations_per_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f05fc37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Hit Rate: {'limit': 5, 'threshold': 0.3, 'hit_rate': 0.898, 'mrr': 0.7617999999999995}\n",
      "Highest MRR: {'limit': 5, 'threshold': 0.3, 'hit_rate': 0.898, 'mrr': 0.7617999999999995}\n"
     ]
    }
   ],
   "source": [
    "format_evaluation_result(results=eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98696f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
