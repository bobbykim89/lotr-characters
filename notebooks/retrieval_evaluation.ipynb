{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa96abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd90e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dist/qdrant_records.json\", 'r') as file:\n",
    "    qdrant_records = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a3b979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_TEMPERATURE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb18bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2253e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt (payload: dict[str,str])-> tuple[str, str]:\n",
    "    raw_user_prompt = \"\"\"\n",
    "Payload:\n",
    "{payload}\n",
    "\"\"\".strip()\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an assistant that generates evaluation questions to test retrieval quality on character data.\n",
    "You will receive a JSON object describing a fictional character, which may include fields such as name, race, gender, birth, death, spouse, realm, biography, and others.\n",
    "\n",
    "Your task:\n",
    "1. Read and understand the JSON payload carefully.\n",
    "2. Generate exactly 5 diverse and specific questions that can be answered using the information in the payload.\n",
    "3. Focus on factual, grounded details — such as relationships, timeline, characteristics, or key events mentioned in the biography.\n",
    "4. Avoid trivial or repetitive questions.\n",
    "5. Do not include any reasoning, explanations, or text outside the JSON array.\n",
    "\n",
    "Output format (JSON only):\n",
    "[\n",
    "\"Question 1?\",\n",
    "\"Question 2?\",\n",
    "\"Question 3?\",\n",
    "\"Question 4?\",\n",
    "\"Question 5?\"\n",
    "]\n",
    "\n",
    "If a field is null or missing, do not ask about it. If there is limited information, create general but relevant questions based on available content.\n",
    "\"\"\".strip()\n",
    "    user_prompt = raw_user_prompt.format(payload=payload).strip()\n",
    "    \n",
    "    return user_prompt, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a5214d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_records ():\n",
    "    formatted_records = []\n",
    "    for record in tqdm(qdrant_records):\n",
    "        basic_fields = ['race', 'gender', 'realm', 'culture', 'birth', 'death', 'spouse', 'hair', 'height', 'biography', 'history']\n",
    "        character = {\n",
    "            \"id\": record[\"id\"]\n",
    "        }\n",
    "        character.update([(field, record[\"payload\"][field]) for field in basic_fields if record[\"payload\"].get(field)])\n",
    "        formatted_records.append(character)\n",
    "\n",
    "    return formatted_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caae4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt: str, system_prompt: str)-> list[str]:\n",
    "    \"\"\"\n",
    "    llm function to call openAI with our specific prompts\n",
    "    \"\"\"\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=OPENAI_TEMPERATURE\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbecad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(ctx: dict[str,str])->list[str]:\n",
    "    user_prompt, system_prompt = format_prompt(ctx)\n",
    "    return llm(user_prompt=user_prompt, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49b64bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 749/749 [00:00<00:00, 240454.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n\"Who is Hareth\\'s spouse?\",\\n\"In which year did Hareth marry Galdor?\",\\n\"What is the name of Hareth\\'s father?\",\\n\"How many children did Hareth have?\",\\n\"Which age of Middle-earth did Hareth live in?\"\\n]'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rau = format_records()\n",
    "generate_question(rau[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c2877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
