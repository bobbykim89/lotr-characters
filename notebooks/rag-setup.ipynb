{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eadd8d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import requests\n",
    "from os import environ\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee54746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = environ.get('QDRANT_CLOUD_URL')\n",
    "QDRANT_API_KEY = environ.get('QDRANT_API_KEY')\n",
    "COLLECTION_NAME = 'lotr-characters'\n",
    "EMBEDDING_DIMENSION = 512\n",
    "JINA_EMBEDDING_MODEL = \"jina-embeddings-v4\"\n",
    "JINA_URL = \"https://api.jina.ai/v1/embeddings\"\n",
    "JINA_API_KEY = environ.get('JINA_API_KEY')\n",
    "QUERYING_TASK = \"retrieval.query\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_TEMPERATURE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8f5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "qd_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ccf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jina_embedding(input_text: str)-> list:\n",
    "    \"\"\"\n",
    "    Create embedding using Jina API\n",
    "    Returns a single embedding vector (list of floats)\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {JINA_API_KEY}\",\n",
    "    }\n",
    "    data = {\n",
    "        \"input\": [input_text],\n",
    "        \"model\": JINA_EMBEDDING_MODEL,\n",
    "        \"dimensions\": EMBEDDING_DIMENSION,\n",
    "        \"task\": QUERYING_TASK,\n",
    "        \"late_chunking\": True,\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(url=JINA_URL, headers=headers, json=data, timeout=30)\n",
    "        if res.status_code == 200:\n",
    "            embedding = res.json()[\"data\"][0][\"embedding\"]\n",
    "            return embedding\n",
    "        else:\n",
    "            raise Exception(f\"Jina API error: {res.status_code} - {res.text}\")\n",
    "    except requests.RequestException as e:\n",
    "        raise Exception(f\"Request failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21a0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, limit: int = 5):\n",
    "    \"\"\"\n",
    "    Updated search function to use Jina API for query embedding\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create embedding for the search query using Jina API\n",
    "        query_embedding = create_jina_embedding(input_text=query)\n",
    "        \n",
    "        query_points = qd_client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=query_embedding,\n",
    "            limit=limit,\n",
    "            with_payload=True\n",
    "        )\n",
    "        results = [point.payload for point in query_points.points]\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9058ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt (query: str, search_results: list[dict[str,str]]):\n",
    "    raw_user_prompt = \"\"\"\n",
    "Context from database:\n",
    "{retrieved_context}\n",
    "\n",
    "User question:\n",
    "{user_question}\n",
    "\n",
    "Answer the question using ONLY the context above.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "You are a helpful lore expert on J.R.R. Tolkien's Middle-earth. \n",
    "You can only answer questions about characters using the provided context retrieved from the database. \n",
    "The context includes structured information such as: name, race, titles, realm, family relations, birth and death dates, and short descriptions.\n",
    "\n",
    "Guidelines:\n",
    "- If the answer is found in the context, respond clearly and directly.\n",
    "- If the answer is not in the context, say you don’t know or that the information was not provided.\n",
    "- Do not invent new facts outside the context.\n",
    "- Keep your answers concise, but include all relevant details from the context.\n",
    "- If the user asks for speculation (e.g., \"what would happen if X met Y?\"), you can summarize based only on what the context says about their traits.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    user_prompt = raw_user_prompt.format(retrieved_context=search_results, user_question=query).strip()\n",
    "    return user_prompt, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc33e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_hits_response(hits: list[dict[str, str|None]]):\n",
    "    \"\"\"Format the results into text to plug into chatGPT\"\"\"\n",
    "    character_data = []\n",
    "    for hit in hits:\n",
    "        basic_fields = ['race', 'gender', 'realm', 'culture', 'birth', 'death', 'spouse', 'hair', 'height', 'biography', 'history']\n",
    "        character = {}\n",
    "        character.update([(field, hit[field]) for field in basic_fields if hit.get(field)])\n",
    "        character_data.append(character)\n",
    "    \n",
    "    return json.dumps(character_data, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e73278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt: str, system_prompt: str):\n",
    "    \"\"\" llm function to call openAI with our specific prompts\"\"\"\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=OPENAI_TEMPERATURE\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3b60fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_lotr(query: str):\n",
    "    hits = search(query=query, limit=6)\n",
    "    formatted_hits = format_hits_response(hits=hits)\n",
    "    user_prompt,system_prompt = build_prompt(query=query, search_results=formatted_hits)\n",
    "    res = llm(user_prompt=user_prompt, system_prompt=system_prompt)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a062ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Witch-king of Angmar was killed by Éowyn during the Battle of the Pelennor Fields. She challenged him, and with the help of Merry, she was able to defeat him, fulfilling the prophecy that he would not fall by the hand of man.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_lotr(query=\"who killed the witch king of angmar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6843c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
