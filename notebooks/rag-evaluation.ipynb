{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ce908b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from tqdm import tqdm\n",
    "from os import environ\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfead1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = environ.get('QDRANT_URL')\n",
    "QDRANT_API_KEY = environ.get('QDRANT_API_KEY')\n",
    "COLLECTION_NAME = 'lotr-characters'\n",
    "EMBEDDING_DIMENSION = 512\n",
    "JINA_EMBEDDING_MODEL = \"jina-embeddings-v4\"\n",
    "JINA_URL = \"https://api.jina.ai/v1/embeddings\"\n",
    "JINA_API_KEY = environ.get('JINA_API_KEY')\n",
    "QUERYING_TASK = \"retrieval.query\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_TEMPERATURE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec3f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "qd_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0b043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_eval_prompt (payload: dict[str,str])-> tuple[str, str]:\n",
    "    raw_user_prompt = \"\"\"\n",
    "Evaluate the following RAG output.\n",
    "{{\n",
    "  \"question\": \"{question}\",\n",
    "  \"context\": \"{context}\",\n",
    "  \"answer\": \"{answer}\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an impartial evaluator assessing the quality of a RAG (Retrieval-Augmented Generation) system that answers questions about J.R.R. Tolkien’s Middle-earth characters.\n",
    "\n",
    "You will receive a JSON input with the following fields:\n",
    "{\n",
    "  \"question\": \"<user query>\",\n",
    "  \"context\": \"<retrieved context>\",\n",
    "  \"answer\": \"<model-generated answer>\"\n",
    "}\n",
    "\n",
    "Your task is to evaluate how well the answer satisfies the question, using only the information in the context.\n",
    "\n",
    "Evaluate on four criteria:\n",
    "1. Relevance — Does the answer directly address the question?\n",
    "2. Groundedness — Are all facts supported by the provided context (no hallucinations)?\n",
    "3. Completeness — Does the answer include all key details from the context?\n",
    "4. Faithfulness — Does it follow the system rules (concise, factual, no invention, admits missing info)?\n",
    "\n",
    "Scoring Guide (0–3 for each):\n",
    "- 3: Excellent — fully meets the criterion\n",
    "- 2: Fair — mostly correct, minor omissions or minor unsupported detail\n",
    "- 1: Weak — noticeable errors, missing or irrelevant info\n",
    "- 0: None — fails completely or contradicts context\n",
    "\n",
    "Your output must be a single valid JSON object:\n",
    "{\n",
    "  \"relevance\": <0–3>,\n",
    "  \"groundedness\": <0–3>,\n",
    "  \"completeness\": <0–3>,\n",
    "  \"faithfulness\": <0–3>,\n",
    "  \"comments\": \"<1–2 sentence summary of reasoning>\"\n",
    "}\n",
    "\n",
    "Output only the JSON object — no markdown, no extra text.\n",
    "\"\"\".strip()\n",
    "    user_prompt = raw_user_prompt.format(question=payload.get('question'), context=payload.get('context'), answer=payload.get('answer')).strip()\n",
    "    \n",
    "    return user_prompt, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfe7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
